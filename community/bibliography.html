<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="prev" title="Frequently Asked Questions" href="faqs.html" />
        <link rel="canonical" href="https://kornia.readthedocs.io/community/bibliography.html" />

    <link rel="shortcut icon" href="../_static/kornia_logo_favicon.png"/><!-- Generated with Sphinx 6.2.1 and Furo 2023.05.20 -->
        <title>Bibliography - Kornia</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=e6660623a769aa55fea372102b9bf3151b292993" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../_static/css/main.css" />
    
    


<style>
  body {
    --color-code-background: #f0f0f0;
  --color-code-foreground: black;
  --color-sidebar-background: #3980F5;
  --color-sidebar-background-border: #3980F5;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  --color-sidebar-link-text: white;
  --sidebar-caption-font-size: normal;
  --color-sidebar-item-background--hover:  #5dade2;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-sidebar-background: #1a1c1e;
  --color-sidebar-background-border: #1a1c1e;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #272822;
  --color-code-foreground: #f8f8f2;
  --color-sidebar-background: #1a1c1e;
  --color-sidebar-background-border: #1a1c1e;
  --color-sidebar-caption-text: white;
  --color-sidebar-link-text--top-level: white;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">Kornia</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo only-light" src="../_static/img/kornia_logo_only_light.svg" alt="Light Logo"/>
    <img class="sidebar-logo only-dark" src="../_static/img/kornia_logo_only_dark.svg" alt="Dark Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">GET STARTED</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get-started/introduction.html">What is Kornia library ?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/highlights.html">Highlighted Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/about.html">About</a></li>
<li class="toctree-l1"><a class="reference external" href="https://kornia-tutorials.readthedocs.io/en/latest/">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/training.html">Training API (experimental)</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.luxonis.com/en/latest/pages/tutorials/creating-custom-nn-models/#kornia">OpenCV AI Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/governance.html">Kornia AI Organization</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API REFERENCE</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../augmentation.html">kornia.augmentation</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle navigation of kornia.augmentation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../augmentation.auto.html">Automatic Augmentation Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augmentation.base.html">Base Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augmentation.container.html">Augmentation Containers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../augmentation.module.html">Image Augmentations</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../color.html">kornia.color</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contrib.html">kornia.contrib</a></li>
<li class="toctree-l1"><a class="reference internal" href="../enhance.html">kornia.enhance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../feature.html">kornia.feature</a></li>
<li class="toctree-l1"><a class="reference internal" href="../filters.html">kornia.filters</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../geometry.html">kornia.geometry</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle navigation of kornia.geometry</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../geometry.bbox.html">kornia.geometry.bbox</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.boxes.html">kornia.geometry.boxes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.keypoints.html">kornia.geometry.keypoints</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.calibration.html">kornia.geometry.calibration</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../geometry.camera.html">kornia.geometry.camera</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle navigation of kornia.geometry.camera</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../geometry.camera.pinhole.html">Pinhole Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="../geometry.camera.perspective.html">Perspective Camera</a></li>
<li class="toctree-l3"><a class="reference internal" href="../geometry.camera.stereo.html">Stereo Camera</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.conversions.html">kornia.geometry.conversions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.depth.html">kornia.geometry.depth</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.epipolar.html">kornia.geometry.epipolar</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.homography.html">kornia.geometry.homography</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.liegroup.html">kornia.geometry.liegroup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.linalg.html">kornia.geometry.linalg</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.line.html">kornia.geometry.line</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.quaternion.html">kornia.geometry.quaternion</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.subpix.html">kornia.geometry.subpix</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.transform.html">kornia.geometry.transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../geometry.ransac.html">kornia.geometry.ransac</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sensors.html">kornia.sensors</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle navigation of kornia.sensors</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../sensors.camera.html">kornia.sensors.camera</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../io.html">kornia.io</a></li>
<li class="toctree-l1"><a class="reference internal" href="../losses.html">kornia.losses</a></li>
<li class="toctree-l1"><a class="reference internal" href="../metrics.html">kornia.metrics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../morphology.html">kornia.morphology</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tracking.html">kornia.tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../testing.html">kornia.testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils.html">kornia.utils</a></li>
<li class="toctree-l1"><a class="reference internal" href="../x.html">kornia.x</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KORNIA APPLICATIONS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../applications/intro.html">Computer Vision Algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/visual_prompting.html">Visual Prompting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/face_detection.html">Face Detection</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/image_augmentations.html">Image Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/image_classification.html">Image Classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/image_matching.html">Image Matching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/image_stitching.html">Image Stitching</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/image_registration.html">Image Registration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/image_denoising.html">Image Denoising</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/semantic_segmentation.html">Semantic segmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../applications/object_detection.html">Object detection</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">KORNIA MODELS</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../models/rt_detr.html">Real-Time Detection Transformer (RT-DETR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/segment_anything.html">Segment Anything (SAM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/mobile_sam.html">Faster Segment Anything (MobileSAM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/yunet.html">YuNet</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/vit.html">Vision Transformer (ViT)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/vit_mobile.html">MobileViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/tiny_vit.html">TinyViT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/loftr.html">LoFTR (matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/defmo.html">DeFMO (video)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/hardnet.html">Hardnet (descriptor)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/affnet.html">Affnet (detection)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/sold2.html">SOLD2 (Line detection and matching)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models/dexined.html">Dexined (edge detection)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SUPPORT</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://github.com/kornia/kornia/issues">Issue tracker</a></li>
<li class="toctree-l1"><a class="reference external" href="https://join.slack.com/t/kornia/shared_invite/zt-csobk21g-2AQRi~X9Uu6PLMuUZdvfjA">Slack community</a></li>
<li class="toctree-l1"><a class="reference external" href="https://librecv.org">LibreCV community</a></li>
<li class="toctree-l1"><a class="reference external" href="https://twitter.com/kornia_foss">Twitter @kornia_foss</a></li>
<li class="toctree-l1"><a class="reference internal" href="chinese.html">Kornia 社区</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.youtube.com/channel/UCI1SE1Ij2Fast5BSKxoa7Ag">Kornia Youtube</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.linkedin.com/company/kornia/">Kornia LinkedIn</a></li>
<li class="toctree-l1"><a class="reference external" href="https://kornia.org">Kornia AI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">COMMUNITY</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="contribute.html">Contribute to Kornia</a></li>
<li class="toctree-l1"><a class="reference internal" href="faqs.html">Frequently Asked Questions</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Bibliography</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="bibliography">
<h1>Bibliography<a class="headerlink" href="#bibliography" title="Permalink to this heading">#</a></h1>
<div class="docutils container" id="id1">
<div class="citation" id="id11" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BRPM16<span class="fn-bracket">]</span></span>
<p>Vassileios Balntas, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Learning local feature descriptors with triplets and shallow convolutional neural networks. In <em>British Machine Vision Conference (BMVC)</em>. 2016.</p>
</div>
<div class="citation" id="id23" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BLRPM19<span class="fn-bracket">]</span></span>
<p>Axel Barroso-Laguna, Edgar Riba, Daniel Ponsa, and Krystian Mikolajczyk. Key.Net: Keypoint Detection by Handcrafted and Learned CNN Filters. In <em>ICCV</em>. 2019.</p>
</div>
<div class="citation" id="id33" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>BA87<span class="fn-bracket">]</span></span>
<p>Peter J Burt and Edward H Adelson. The laplacian pyramid as a compact image code. In <em>Readings in computer vision</em>, pages 671–679. Elsevier, 1987.</p>
</div>
<div class="citation" id="id34" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CLO+20<span class="fn-bracket">]</span></span>
<p>Luca Cavalli, Viktor Larsson, Martin Ralf Oswald, Torsten Sattler, and Marc Pollefeys. Adalam: revisiting handcrafted outlier detection. <em>CoRR</em>, 2020. URL: <a class="reference external" href="https://arxiv.org/abs/2006.04250">https://arxiv.org/abs/2006.04250</a>, <a class="reference external" href="https://arxiv.org/abs/2006.04250">arXiv:2006.04250</a>.</p>
</div>
<div class="citation" id="id36" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CZM+18<span class="fn-bracket">]</span></span>
<p>Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: learning augmentation policies from data. <em>arXiv preprint arXiv:1805.09501</em>, 2018.</p>
</div>
<div class="citation" id="id37" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>CZSL20<span class="fn-bracket">]</span></span>
<p>Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment: practical automated data augmentation with a reduced search space. In <em>Proceedings of the IEEE/CVF conference on computer vision and pattern recognition workshops</em>, 702–703. 2020.</p>
</div>
<div class="citation" id="id2" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>DBK+21<span class="fn-bracket">]</span></span>
<p>Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. An image is worth 16x16 words: transformers for image recognition at scale. <em>ICLR</em>, 2021.</p>
</div>
<div class="citation" id="id24" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>FYP+21<span class="fn-bracket">]</span></span>
<p>Yuantao Feng, Shiqi Yu, Hanyang Peng, Yan-ran Li, and Jianguo Zhang. Detect faces efficiently: a survey and evaluations. <em>IEEE Transactions on Biometrics, Behavior, and Identity Science</em>, 2021.</p>
</div>
<div class="citation" id="id41" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HS15<span class="fn-bracket">]</span></span>
<p>Kaiming He and Jian Sun. Fast guided filter. 2015. <a class="reference external" href="https://arxiv.org/abs/1505.00996">arXiv:1505.00996</a>.</p>
</div>
<div class="citation" id="id40" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>HST10<span class="fn-bracket">]</span></span>
<p>Kaiming He, Jian Sun, and Xiaoou Tang. Guided image filtering. In <em>Proceedings of the 11th European Conference on Computer Vision: Part I</em>, 1–14. 2010.</p>
</div>
<div class="citation" id="id30" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>JJC01<span class="fn-bracket">]</span></span>
<p>Guerrero J.J. and Sagues C. From lines to homographies between uncalibrated images. In <em>IX Spanish Symposium on Pattern Recognition and Image Analysis</em>. 2001.</p>
</div>
<div class="citation" id="id21" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>KS19<span class="fn-bracket">]</span></span>
<p>Davood Karimi and Septimiu E Salcudean. Reducing the hausdorff distance in medical image segmentation with convolutional neural networks. <em>IEEE Transactions on medical imaging</em>, 39(2):499–513, 2019.</p>
</div>
<div class="citation" id="id19" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LYFC21<span class="fn-bracket">]</span></span>
<p>Shiqi Lin, Tao Yu, Ruoyu Feng, and Zhibo Chen. Patch autoaugment. 2021. <a class="reference external" href="https://arxiv.org/abs/2103.11099">arXiv:2103.11099</a>.</p>
</div>
<div class="citation" id="id16" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LGG+18<span class="fn-bracket">]</span></span>
<p>Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Dollár. Focal loss for dense object detection. <em>arXiv ePrint 1708.02002</em>, 2018.</p>
</div>
<div class="citation" id="id9" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>LSP23<span class="fn-bracket">]</span></span>
<p>Philipp Lindenberger, Paul-Edouard Sarlin, and Marc Pollefeys. Lightglue: local feature matching at light speed. <em>arXiv ePrint 2306.13643</em>, 2023.</p>
</div>
<div class="citation" id="id22" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MarquezNLopezABB16<span class="fn-bracket">]</span></span>
<p>Pablo Márquez-Neila, Javier López-Alberca, José M. Buenaposada, and Luis Baumela. Speeding-up homography estimation in mobile devices. <em>J. Real-Time Image Process.</em>, 11(1):141–154, January 2016. URL: <a class="reference external" href="https://doi.org/10.1007/s11554-012-0314-1">https://doi.org/10.1007/s11554-012-0314-1</a>, <a class="reference external" href="https://doi.org/10.1007/s11554-012-0314-1">doi:10.1007/s11554-012-0314-1</a>.</p>
</div>
<div class="citation" id="id6" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MMRM17<span class="fn-bracket">]</span></span>
<p>Anastasiya Mishchuk, Dmytro Mishkin, Filip Radenovic, and Jiri Matas. Working hard to know your neighbor's margins: local descriptor learning loss. In <em>Proceedings of NeurIPS</em>. 2017.</p>
</div>
<div class="citation" id="id14" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MRM18<span class="fn-bracket">]</span></span>
<p>D. Mishkin, F. Radenovic, and J. Matas. Repeatability is Not Enough: Learning Affine Regions via Discriminability. In <em>ECCV</em>. 2018.</p>
</div>
<div class="citation" id="id32" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MMP15<span class="fn-bracket">]</span></span>
<p>Dmytro Mishkin, Jiri Matas, and Michal Perdoch. Mods: fast and robust method for two-view matching. <em>Computer Vision and Image Understanding</em>, 141:81 – 93, 2015.</p>
</div>
<div class="citation" id="id12" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MTB+19<span class="fn-bracket">]</span></span>
<p>Arun Mukundan, Giorgos Tolias, Andrei Bursuc, Hervé Jégou, and Ondřej Chum. Understanding and improving kernel local descriptors. <em>International Journal of Computer Vision</em>, 2019.</p>
</div>
<div class="citation" id="id38" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>MullerH21<span class="fn-bracket">]</span></span>
<p>Samuel G Müller and Frank Hutter. Trivialaugment: tuning-free yet state-of-the-art data augmentation. In <em>Proceedings of the IEEE/CVF international conference on computer vision</em>, 774–782. 2021.</p>
</div>
<div class="citation" id="id31" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>NCR+22<span class="fn-bracket">]</span></span>
<p>Anguelos Nicolaou, Vincent Christlein, Edgar Riba, Jian Shi, Georg Vogeler, and Mathias Seuret. Tormentor: deterministic dynamic-path, data augmentations with fractals. 2022. URL: <a class="reference external" href="https://arxiv.org/abs/2204.03776">https://arxiv.org/abs/2204.03776</a>, <a class="reference external" href="https://doi.org/10.48550/ARXIV.2204.03776">doi:10.48550/ARXIV.2204.03776</a>.</p>
</div>
<div class="citation" id="id26" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PautratLinL+21<span class="fn-bracket">]</span></span>
<p>Rémi Pautrat*, Juan-Ting Lin*, Viktor Larsson, Martin R. Oswald, and Marc Pollefeys. Sold2: self-supervised occlusion-aware line description and detection. In <em>Computer Vision and Pattern Recognition (CVPR)</em>. 2021.</p>
</div>
<div class="citation" id="id28" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>PDP20<span class="fn-bracket">]</span></span>
<p>Duc Duy Pham, Gurbandurdy Dovletov, and Josef Pauli. A differentiable convolutional distance transform layer for improved image segmentation. <em>Pattern Recognition</em>, 12544:432 – 444, 2020.</p>
</div>
<div class="citation" id="id7" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Pul20<span class="fn-bracket">]</span></span>
<p>Milan Pultar. Improving the hardnet descriptor. <em>arXiv ePrint 2007.09699</em>, 2020.</p>
</div>
<div class="citation" id="id3" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ROF+21<span class="fn-bracket">]</span></span>
<p>Denys Rozumnyi, Martin R. Oswald, Vittorio Ferrari, Jiri Matas, and Marc Pollefeys. Defmo: deblurring and shape recovery of fast moving objects. In <em>CVPR</em>. 2021.</p>
</div>
<div class="citation" id="id17" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SEG17<span class="fn-bracket">]</span></span>
<p>Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali Gholipour. Tversky loss function for image segmentation using 3d fully convolutional deep networks. <em>arXiv ePrint 1706.05721</em>, 2017.</p>
</div>
<div class="citation" id="id18" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SSP03<span class="fn-bracket">]</span></span>
<p>P. Simard, David Steinkraus, and John C. Platt. Best practices for convolutional neural networks applied to visual document analysis. <em>Seventh International Conference on Document Analysis and Recognition, 2003. Proceedings.</em>, pages 958–963, 2003.</p>
</div>
<div class="citation" id="id8" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SK20<span class="fn-bracket">]</span></span>
<p>Saurabh Singh and Shankar Krishnan. Filter response normalization layer: eliminating batch dependence in the training of deep neural networks. In <em>CVPR</em>. 2020.</p>
</div>
<div class="citation" id="id25" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SRS20<span class="fn-bracket">]</span></span>
<p>X. Soria, E. Riba, and A. Sappa. Dense extreme inception network: towards a robust cnn model for edge detection. In <em>2020 IEEE Winter Conference on Applications of Computer Vision (WACV)</em>, volume, 1912–1921. Los Alamitos, CA, USA, mar 2020. IEEE Computer Society. URL: <a class="reference external" href="https://doi.ieeecomputersociety.org/10.1109/WACV45572.2020.9093290">https://doi.ieeecomputersociety.org/10.1109/WACV45572.2020.9093290</a>, <a class="reference external" href="https://doi.org/10.1109/WACV45572.2020.9093290">doi:10.1109/WACV45572.2020.9093290</a>.</p>
</div>
<div class="citation" id="id20" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>SSW+21<span class="fn-bracket">]</span></span>
<p>Jiaming Sun, Zehong Shen, Yuang Wang, Hujun Bao, and Xiaowei Zhou. LoFTR: detector-free local feature matching with transformers. In <em>CVPR</em>. 2021.</p>
</div>
<div class="citation" id="id10" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>TBLN+20<span class="fn-bracket">]</span></span>
<p>Yurun Tian, Axel Barroso Laguna, Tony Ng, Vassileios Balntas, and Krystian Mikolajczyk. Hynet: learning local descriptor with hybrid similarity measure and triplet loss. In <em>NeurIPS</em>. 2020.</p>
</div>
<div class="citation" id="id39" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>TFT20<span class="fn-bracket">]</span></span>
<p>Michał Tyszkiewicz, Pascal Fua, and Eduard Trulls. Disk: learning local features with policy gradient. <em>Advances in Neural Information Processing Systems</em>, 33:14254–14265, 2020.</p>
</div>
<div class="citation" id="id15" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>YHO+19<span class="fn-bracket">]</span></span>
<p>Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe, and Youngjoon Yoo. Cutmix: regularization strategy to train strong classifiers with localizable features. In <em>International Conference on Computer Vision (ICCV)</em>. 2019.</p>
</div>
<div class="citation" id="id13" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ZnYNDLP18<span class="fn-bracket">]</span></span>
<p>Hongyi Zhang, Moustapha Cisse nad Yann N. Dauphin, and David Lopez-Paz. Mixup: beyond empirical risk minimization. <em>International Conference on Learning Representations</em>, 2018. URL: <a class="reference external" href="https://openreview.net/forum?id=r1Ddp1-Rb">https://openreview.net/forum?id=r1Ddp1-Rb</a>.</p>
</div>
<div class="citation" id="id4" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Zha19<span class="fn-bracket">]</span></span>
<p>Richard Zhang. Making convolutional networks shift-invariant again. In <em>ICML</em>. 2019.</p>
</div>
<div class="citation" id="id29" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>ZBTvdW22<span class="fn-bracket">]</span></span>
<p>Simone Zini, Marco Buzzelli, Bartłomiej Twardowski, and Joost van de Weijer. Planckian jitter: enhancing the color quality of self-supervised visual representations. <em>arXiv preprint arXiv:2202.07993</em>, 2022.</p>
</div>
<div class="citation" id="id5" role="doc-biblioentry">
<span class="label"><span class="fn-bracket">[</span>Baumberg00<span class="fn-bracket">]</span></span>
<p>A. Baumberg. Reliable feature matching across widely separated views. In <em>CVPR</em>. 2000.</p>
</div>
</div>
</div>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          <a class="prev-page" href="faqs.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Frequently Asked Questions</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2019, Kornia developers
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div>
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script src="../_static/js/custom.js"></script>
    
    <!-- DocsQA integration start -->
    <script src="https://jina-docqa-ui.netlify.app/dist/qabot.js"></script>
    <script type="module" src="https://gradio.s3-us-west-2.amazonaws.com/3.3.1/gradio.js"></script>
    <script>
      // This prevents the global search interfere with qa-bot internal text input.
      document.addEventListener('DOMContentLoaded', () => {
        document.querySelectorAll('qa-bot').forEach((x) => {
          x.addEventListener('keydown', (event) => {
            event.stopPropagation();
          });
        });
      });
    </script>
    <qa-bot
        token="_LX-ltnplMGK5qrT05qV-auHldTT_babktyfuL2Gn8aP9_eDldufuLiA"
        title="Kornia"
        description="State-of-the-art and curated Computer Vision algorithms for AI"
        avatar-src="https://github.com/kornia/data/raw/main/pixie_QAbot.png">
            <template>
                <dl>
                    <dt>You can ask questions about Kornia. Try</dt>
                    <dd>What is Kornia?</dd>
                    <dd>How can i find correspondences between two images?</dd>
                    <dd>How to do image augmentation?</dd>
                </dl>
            </template>
    </qa-bot>
    <!-- DocsQA integration end -->
</body>
</html>